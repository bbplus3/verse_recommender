{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba23d72-4802-4ebb-94cf-4f9065db1a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings and FAISS index saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import faiss\n",
    "\n",
    "# Load Bible Data\n",
    "df = pd.read_csv(\"t_bbe.csv\")  # Ensure CSV has a \"text\", \"book\", \"chapter\", and \"verse\" column\n",
    "book_names = {1:'Genesis',2:'Exodus',3:'Leviticus',4:'Numbers',5:'Deuteronomy',6:'Joshua',7:'Judges',8:'Ruth',9:'1 Samuel',10:'2 Samuel',11:'1 Kings',12:'2 Kings',13:'1 Chronicles',14:'2 Chronicles',15:'Ezra',16:'Nehemiah',17:'Esther',18:'Job',19:'Psalms',20:'Proverbs',21:'Ecclesiastes',22:'Song of Solomon',23:'Isaiah',24:'Jeremiah',25:'Lamentations',26:'Ezekiel',27:'Daniel',28:'Hosea',29:'Joel',30:'Amos',31:'Obadiah',32:'Jonah',33:'Micah',34:'Nahum',35:'Habakkuk',36:'Zephaniah',37:'Haggai',38:'Zechariah',39:'Malachi',40:'Matthew',41:'Mark',42:'Luke',43:'John',44:'Acts',45:'Romans',46:'1 Corinthians',47:'2 Corinthians',48:'Galatians',49:'Ephesians',50:'Philippians',51:'Colossians',52:'1 Thessalonians',53:'2 Thessalonians',54:'1 Timothy',55:'2 Timothy',56:'Titus',57:'Philemon',58:'Hebrews',59:'James',60:'1 Peter',61:'2 Peter',62:'1 John',63:'2 John',64:'3 John',65:'Jude',66:'Revelation'}\n",
    "\n",
    "# Map book names to dataframe\n",
    "df['Book Name'] = df['b'].map(book_names)\n",
    "\n",
    "# Load Sentence-BERT model\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to compute embeddings\n",
    "def get_embedding(text):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    return output.last_hidden_state[:, 0, :].numpy()  # Use [CLS] token\n",
    "\n",
    "# Compute embeddings\n",
    "embeddings = np.vstack(df[\"t\"].apply(get_embedding).values)\n",
    "\n",
    "# Save embeddings and FAISS index\n",
    "np.save(\"bible_embeddings.npy\", embeddings)  # Save embeddings\n",
    "df.to_csv(\"bible_verses_processed.csv\", index=False)  # Save processed verses\n",
    "\n",
    "# Save FAISS index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "faiss.write_index(index, \"bible_faiss.index\")\n",
    "\n",
    "print(\"✅ Embeddings and FAISS index saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dfb692-02eb-4d26-a5a3-f1a92f99e92d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
